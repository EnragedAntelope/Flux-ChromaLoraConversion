# Flux to Chroma LoRA Converter - Advanced Version

**âš ï¸ BETA SOFTWARE - Now with Advanced Interpolation Methods**

An advanced Python script that converts Flux Dev LoRAs to work with the Chroma model using sophisticated interpolation techniques including comparative interpolation and add dissimilar operations, based on techniques from model merging research.

## ðŸš€ What's New in the Advanced Version

### Advanced Interpolation Methods
- **Comparative Interpolation**: Uses similarity-based interpolation with controlled random distribution for better texture preservation
- **Add Dissimilar Operation**: Enhances regions where models differ most, preserving unique characteristics
- **Adaptive Strength**: Automatically adjusts merge strength based on layer similarity
- **Random Distribution Clamped**: Adds controlled noise to prevent over-smoothing and preserve detail

### Why These Methods?
Based on advanced model merging techniques, these methods:
- Better preserve the unique characteristics of your LoRA
- Reduce quality loss during conversion
- Handle dissimilar regions more intelligently
- Add controlled randomness to maintain texture and detail

## âš ï¸ Important Limitations (Still Apply)

### Architectural Reality
- **Flux Dev** (12B parameters) vs **Chroma** (8.9B parameters, based on Flux Schnell)
- **Expected success rate: ~20-35%** with advanced methods (improved from 15-25%)
- **Fundamental incompatibilities still exist**:
  - Different transformer architectures
  - Parameter count mismatch
  - Some layers simply don't map

### What This Means
- âœ… **Better effect preservation** - Advanced methods capture more nuance
- âœ… **Improved texture/detail retention** - Random distribution helps
- âš ï¸ **Still not perfect** - Architectural limits remain
- âŒ **Some LoRAs still won't convert well** - Especially complex ones

## Installation

### Requirements
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install safetensors numpy tqdm
```

### System Requirements
- **GPU**: 8GB+ VRAM recommended (can run on CPU but very slow)
- **RAM**: 16GB+ system RAM
- **Storage**: ~20GB free space for model files and intermediates

## Usage

### Quick Start with Advanced Features

```bash
python flux-chroma-converter-advanced.py \
  --flux-model /path/to/flux_dev.safetensors \
  --chroma-model /path/to/chroma.safetensors \
  --lora /path/to/your_flux_lora.safetensors \
  --output /path/to/output_chroma_lora.safetensors \
  --use-comparative-interpolation \
  --adaptive-strength
```

### Recommended Settings for Different LoRA Types

#### Character LoRAs
```bash
python flux-chroma-converter-advanced.py \
  --flux-model flux_dev.safetensors \
  --chroma-model chroma.safetensors \
  --lora character_lora.safetensors \
  --output converted_character.safetensors \
  --use-comparative-interpolation \
  --adaptive-strength \
  --interpolation-noise-scale 0.02 \
  --dissimilarity-threshold 0.15 \
  --amplify 1.3 \
  --rank 64
```

#### Style LoRAs
```bash
python flux-chroma-converter-advanced.py \
  --flux-model flux_dev.safetensors \
  --chroma-model chroma.safetensors \
  --lora style_lora.safetensors \
  --output converted_style.safetensors \
  --use-comparative-interpolation \
  --adaptive-strength \
  --interpolation-noise-scale 0.03 \
  --dissimilarity-threshold 0.1 \
  --amplify 1.5 \
  --aggressive-mapping \
  --rank 96
```

#### Weak/Subtle LoRAs
```bash
python flux-chroma-converter-advanced.py \
  --flux-model flux_dev.safetensors \
  --chroma-model chroma.safetensors \
  --lora subtle_lora.safetensors \
  --output converted_subtle.safetensors \
  --use-comparative-interpolation \
  --adaptive-strength \
  --interpolation-noise-scale 0.05 \
  --dissimilarity-threshold 0.05 \
  --amplify 2.0 \
  --force-extract-all \
  --aggressive-mapping \
  --threshold 1e-8
```

## Command Line Options

### Required Parameters
- `--flux-model`: Path to Flux Dev UNet model file
- `--chroma-model`: Path to Chroma UNet model file  
- `--lora`: Path to Flux LoRA to convert
- `--output`: Output path (file or directory)

### Core Settings
- `--device cuda|cpu`: Processing device (default: cuda)
- `--dtype float32|float16|bfloat16`: Computation precision (default: bfloat16)
- `--rank N`: Output LoRA rank (default: 64, try 32-128)
- `--merge-strength 0.0-2.0`: Merge intensity (default: 1.0)

### Enhancement Options
- `--amplify 1.0-3.0`: Amplify weak LoRA effects (default: 1.0)
- `--aggressive-mapping`: Try more mapping strategies
- `--force-extract-all`: Extract even tiny differences
- `--threshold 1e-6`: Difference threshold (lower = more sensitive)

### Advanced Interpolation Options (NEW)
- `--use-comparative-interpolation`: Enable advanced interpolation methods (RECOMMENDED)
- `--adaptive-strength`: Automatically adjust strength based on layer similarity
- `--interpolation-noise-scale 0.0-0.1`: Random noise scale (default: 0.02)
  - Lower values (0.01-0.02): Subtle texture preservation
  - Higher values (0.03-0.05): More aggressive detail retention
- `--dissimilarity-threshold 0.0-1.0`: Threshold for enhancing dissimilar regions (default: 0.1)
  - Lower values (0.05-0.1): More aggressive enhancement
  - Higher values (0.15-0.3): More conservative enhancement
- `--interpolation-clamp-range 1.0-5.0`: Clamping range for random distribution (default: 2.0)

### Debugging & Storage
- `--debug-keys`: Show detailed key mapping information
- `--save-intermediate`: Save intermediate conversion steps
- `--intermediate-dir ./path`: Where to save intermediates
- `--chunk-size N`: Memory management (default: 100)

## Understanding the Advanced Methods

### Comparative Interpolation
Instead of simple linear interpolation, this method:
1. Calculates similarity between source and target tensors
2. Applies adaptive interpolation based on similarity
3. Adds controlled random noise to preserve texture
4. Uses clamped distribution to prevent artifacts

### Add Dissimilar Operation
This operation:
1. Identifies regions where models differ most
2. Enhances these regions to preserve unique characteristics
3. Helps maintain LoRA's distinctive features
4. Prevents over-smoothing of important details

### Adaptive Strength
Automatically adjusts the merge strength based on:
- Layer-by-layer similarity analysis
- Higher strength for dissimilar layers
- Lower strength for similar layers
- Helps preserve balance across the model

## Example Workflows

### 1. Maximum Quality Conversion
```bash
# Use all advanced features for best quality
python flux-chroma-converter-advanced.py \
  --flux-model flux_dev.safetensors \
  --chroma-model chroma.safetensors \
  --lora my_lora.safetensors \
  --output high_quality_conversion.safetensors \
  --use-comparative-interpolation \
  --adaptive-strength \
  --interpolation-noise-scale 0.025 \
  --dissimilarity-threshold 0.12 \
  --amplify 1.4 \
  --aggressive-mapping \
  --rank 96 \
  --save-intermediate \
  --debug-keys
```

### 2. Fast Conversion with Good Results
```bash
# Balanced settings for speed and quality
python flux-chroma-converter-advanced.py \
  --flux-model flux_dev.safetensors \
  --chroma-model chroma.safetensors \
  --lora my_lora.safetensors \
  --output quick_conversion.safetensors \
  --use-comparative-interpolation \
  --adaptive-strength \
  --amplify 1.2
```

### 3. Batch Processing with Advanced Features
```bash
# Process multiple LoRAs with advanced methods
for lora in /path/to/flux_loras/*.safetensors; do
    python flux-chroma-converter-advanced.py \
      --flux-model flux_dev.safetensors \
      --chroma-model chroma.safetensors \
      --lora "$lora" \
      --output ./converted_loras/ \
      --use-comparative-interpolation \
      --adaptive-strength \
      --interpolation-noise-scale 0.02 \
      --amplify 1.3
done
```

## Expected Results by LoRA Type (Advanced Version)

| LoRA Type | Conversion Success | Recommended Advanced Settings |
|-----------|-------------------|------------------------------|
| **Character** | ðŸŸ¢ Good (25-45%) | `--use-comparative-interpolation --adaptive-strength --noise-scale 0.02` |
| **Art Style** | ðŸŸ¡ Moderate (20-35%) | `--use-comparative-interpolation --noise-scale 0.03 --dissimilarity 0.1` |
| **Photography** | ðŸŸ¡ Improved (15-25%) | `--use-comparative-interpolation --noise-scale 0.04 --amplify 2.0` |
| **Pose/Composition** | ðŸ”´ Still Poor (10-15%) | All advanced features + `--force-extract-all` |
| **Concept/Object** | ðŸŸ¡ Variable (15-35%) | `--adaptive-strength --aggressive-mapping` |

## Troubleshooting Advanced Features

### Noisy/Artifacts in Output
```bash
# Reduce noise scale
--interpolation-noise-scale 0.01
# or increase clamp range
--interpolation-clamp-range 3.0
```

### Still Weak Effects
```bash
# Increase dissimilarity enhancement
--dissimilarity-threshold 0.05
# and increase amplification
--amplify 2.5
```

### Conversion Too Slow
```bash
# Disable comparative interpolation for speed
# (removes --use-comparative-interpolation)
# or reduce chunk size
--chunk-size 50
```

### Understanding Console Output

```
Using advanced interpolation methods
  - Noise scale: 0.02
  - Dissimilarity threshold: 0.1
  - Clamp range: 2.0
  - Adaptive strength enabled

Applied comparative interpolation with 15 dissimilar enhancements
Enhanced 8 dissimilar layers during extraction
```

## Tips for Best Results

1. **Always use `--use-comparative-interpolation`** for quality conversions
2. **Enable `--adaptive-strength`** for balanced results
3. **Start with default noise scale (0.02)** and adjust if needed
4. **For subtle LoRAs**, increase noise scale to 0.03-0.05
5. **For strong LoRAs**, decrease noise scale to 0.01-0.015
6. **Monitor dissimilar enhancements** - 10-30% is ideal

## Technical Details

### How Comparative Interpolation Works
```python
# Simplified pseudocode
similarity = calculate_cosine_similarity(base, target)
dissimilarity = 1.0 - abs(similarity)
noise = random_normal() * noise_scale * dissimilarity
noise = clamp(noise, -clamp_range, clamp_range)
result = base + alpha * difference + noise
```

### How Add Dissimilar Works
```python
# Simplified pseudocode
difference = abs(tensor1 - tensor2)
mask = difference > threshold
enhancement = 1.0 + difference * amplify_strength
result = tensor1 * enhancement where mask else tensor1
```

## Contributing

This advanced version implements techniques inspired by model merging research. Areas for improvement:

- Additional interpolation methods
- Better similarity metrics
- Automatic parameter tuning
- Support for more model architectures

## License

MIT License - Use at your own risk

## Acknowledgments

Special thanks to silveroxides for suggesting the comparative interpolation and add dissimilar techniques from their model merging work.

## Disclaimer

This tool provides experimental conversion between incompatible architectures. While the advanced methods improve results, perfect conversion remains impossible due to fundamental architectural differences. For production use, training directly on Chroma is still recommended.

---

**ðŸ”— Need Help?**
- Try the recommended settings for your LoRA type
- Experiment with noise scale (0.01-0.05 range)
- Join the community discussions for tips and tricks
- Consider training directly on Chroma for perfect compatibility